{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYSS30vl-1Vs",
        "outputId": "b85cda14-974d-4c3b-bec3-d449167422d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==2.3.1 in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision==0.18.1 in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (2.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.1) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.1) (9.4.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.1) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.3.1 torchvision==0.18.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LasUjzf2I1m6",
        "outputId": "5df8ef77-627b-4ff7-9273-58eeaf57a8da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Epoch [1/5], Loss: 1.7194, Accuracy: 0.3774\n",
            "Epoch [2/5], Loss: 1.1789, Accuracy: 0.5776\n",
            "Epoch [3/5], Loss: 0.8534, Accuracy: 0.7012\n",
            "Epoch [4/5], Loss: 0.6738, Accuracy: 0.7639\n",
            "Epoch [5/5], Loss: 0.5363, Accuracy: 0.8126\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import Compose, ToTensor, Resize\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define transforms\n",
        "transform = Compose([\n",
        "    Resize((128, 128)),  # Resize images to a more manageable size\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "dataset = CIFAR10(root='data/cifar10', train=True, download=True, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=2)  # Use multiple workers\n",
        "\n",
        "# Define YOLO-like model for CIFAR-10\n",
        "class C2f(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, shortcut=True):\n",
        "        super(C2f, self).__init__()\n",
        "        self.shortcut = shortcut\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        if self.shortcut:\n",
        "            out += identity\n",
        "        return F.relu(out)\n",
        "\n",
        "class YOLOv8(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(YOLOv8, self).__init__()\n",
        "        self.backbone = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            C2f(128, 128),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            C2f(256, 256),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            C2f(512, 512),\n",
        "        )\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Conv2d(512, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            C2f(256, 256),\n",
        "            nn.Conv2d(256, num_classes, kernel_size=1)  # Output channels should be num_classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.head(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output for classification\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "model = YOLOv8(num_classes=10)  # CIFAR-10 has 10 classes\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # Use CrossEntropyLoss for classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train(model, dataloader, criterion, optimizer, epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        all_labels = []\n",
        "        all_preds = []\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
        "\n",
        "        # Print average loss and accuracy\n",
        "        avg_loss = running_loss / len(dataloader)\n",
        "        accuracy = accuracy_score(all_labels, all_preds)\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Train the model\n",
        "train(model, dataloader, criterion, optimizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below is Much Better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGGqjx88O1Af",
        "outputId": "104e8733-78e8-457a-d73d-a7a3268c22ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Epoch [1/5], Loss: 1.7701, Train Accuracy: 0.3539, Val Accuracy: 0.5200\n",
            "Model saved with best validation accuracy\n",
            "Epoch [2/5], Loss: 1.2001, Train Accuracy: 0.5675, Val Accuracy: 0.6104\n",
            "Model saved with best validation accuracy\n",
            "Epoch [3/5], Loss: 0.9336, Train Accuracy: 0.6692, Val Accuracy: 0.6507\n",
            "Model saved with best validation accuracy\n",
            "Epoch [4/5], Loss: 0.7540, Train Accuracy: 0.7341, Val Accuracy: 0.7321\n",
            "Model saved with best validation accuracy\n",
            "Epoch [5/5], Loss: 0.6165, Train Accuracy: 0.7847, Val Accuracy: 0.7399\n",
            "Model saved with best validation accuracy\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import Compose, ToTensor, Resize, Normalize\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define transforms\n",
        "transform = Compose([\n",
        "    Resize((128, 128)),  # Resize images to a more manageable size\n",
        "    ToTensor(),\n",
        "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize images\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "dataset = CIFAR10(root='data/cifar10', train=True, download=True, transform=transform)\n",
        "\n",
        "# Split dataset into training and validation sets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define YOLO-like model for CIFAR-10\n",
        "class C2f(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, shortcut=True):\n",
        "        super(C2f, self).__init__()\n",
        "        self.shortcut = shortcut\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        if self.shortcut:\n",
        "            out += identity\n",
        "        return F.relu(out)\n",
        "\n",
        "class YOLOv8(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(YOLOv8, self).__init__()\n",
        "        self.backbone = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            C2f(128, 128),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            C2f(256, 256),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            C2f(512, 512),\n",
        "        )\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Conv2d(512, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            C2f(256, 256),\n",
        "            nn.Conv2d(256, num_classes, kernel_size=1)  # Output channels should be num_classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.head(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output for classification\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "model = YOLOv8(num_classes=10)  # CIFAR-10 has 10 classes\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # Use CrossEntropyLoss for classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Define learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, epochs=5):\n",
        "    best_accuracy = 0.0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        all_labels = []\n",
        "        all_preds = []\n",
        "        for images, labels in train_dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        # Validate model\n",
        "        model.eval()\n",
        "        val_labels = []\n",
        "        val_preds = []\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_dataloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                val_labels.extend(labels.cpu().numpy())\n",
        "                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
        "\n",
        "        # Calculate accuracy\n",
        "        avg_loss = running_loss / len(train_dataloader)\n",
        "        train_accuracy = accuracy_score(all_labels, all_preds)\n",
        "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, '\n",
        "              f'Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "        # Save the model with the best validation accuracy\n",
        "        if val_accuracy > best_accuracy:\n",
        "            best_accuracy = val_accuracy\n",
        "            torch.save(model.state_dict(), 'best_yolov8_cifar10.pth')\n",
        "            print('Model saved with best validation accuracy')\n",
        "\n",
        "# Train the model\n",
        "train(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V83iaSpZLUEB",
        "outputId": "c230b689-3e97-4316-bd89-e8c1a8830bc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved as yolov8_cifar10_new.pth\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def save_model(model, model_path):\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(f\"Model saved as {model_path}\")\n",
        "\n",
        "# Example usage after training the model\n",
        "model = YOLOv8(num_classes=10)\n",
        "# Assuming you've trained the model and it's ready to be saved\n",
        "save_model(model, 'yolov8_cifar10_new.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWXtuMfGRj0Y",
        "outputId": "818610b3-30e5-4226-d73b-bbd636af596a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted class index: 8\n",
            "Predicted class label: Ship\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Define CIFAR-10 class labels\n",
        "class_labels = [\n",
        "    'Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck'\n",
        "]\n",
        "\n",
        "def load_and_preprocess_image(image_path):\n",
        "    # Define preprocessing transformations\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),  # Resize to 128x128\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize images\n",
        "    ])\n",
        "\n",
        "    # Load image\n",
        "    image = Image.open(image_path).convert('RGB')  # Ensure image is in RGB format\n",
        "    # Apply transformations\n",
        "    image = transform(image)\n",
        "    # Add batch dimension\n",
        "    image = image.unsqueeze(0)\n",
        "    return image\n",
        "\n",
        "def load_model(model_path, num_classes=10):\n",
        "    model = YOLOv8(num_classes=num_classes)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    return model\n",
        "\n",
        "def predict_image(image_path, model, device):\n",
        "    image = load_and_preprocess_image(image_path)\n",
        "    image = image.to(device)\n",
        "    model.to(device)\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        pred = torch.argmax(outputs, dim=1)\n",
        "    return pred.item()\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    image_path = '/content/ship.jpg'\n",
        "    model_path = 'best_yolov8_cifar10.pth'\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Load the model\n",
        "    model = load_model(model_path, num_classes=10)\n",
        "\n",
        "    # Predict\n",
        "    predicted_class_index = predict_image(image_path, model, device)\n",
        "\n",
        "    # Get class label\n",
        "    predicted_class_label = class_labels[predicted_class_index]\n",
        "\n",
        "    print(f\"Predicted class index: {predicted_class_index}\")\n",
        "    print(f\"Predicted class label: {predicted_class_label}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "Welcome To Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
